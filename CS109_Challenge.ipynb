{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bachmanmp/cs109/blob/main/CS109_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyO-N3l0WoLX",
        "outputId": "ef8a7a65-ea0e-45e0-dcde-c1bcc9c4f40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gmplot\n",
            "  Downloading gmplot-1.4.1-py3-none-any.whl (164 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/164.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m163.8/164.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.7/164.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gmplot) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gmplot) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gmplot) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gmplot) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gmplot) (2024.2.2)\n",
            "Installing collected packages: gmplot\n",
            "Successfully installed gmplot-1.4.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.interface (from datetime)\n",
            "  Downloading zope.interface-6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.5/247.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from datetime) (2023.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime) (67.7.2)\n",
            "Installing collected packages: zope.interface, datetime\n",
            "Successfully installed datetime-5.5 zope.interface-6.4\n"
          ]
        }
      ],
      "source": [
        "!pip install gmplot\n",
        "!pip install pandas\n",
        "!pip install datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj29Y-6dpnpj",
        "outputId": "0efeeeef-8996-490a-db69-cdc97644fcf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crunching dataset\n",
            "Generated Google Maps visual: car_crashes.html\n",
            "Generated Google Maps visual: bike_crashes.html\n",
            "Summary Stats\n",
            "Time Period for Analysis (in Days):  872\n",
            "Time Period for each Lambda:  day\n",
            "---------------\n",
            "Maximum Likelihood Estimation (Car, Bike, Pedestrian Crash Rates)\n",
            "Overall Car Crash Lambda:  8.605504587155963\n",
            "Overall Bike/Pedestrian Involvement Lambda:  1.136467889908257\n",
            "Joint Lambda\n",
            "{('Clear', 'Dark'): 3.1559633027522938, ('Clear', 'Daylight'): 4.7672018348623855, ('Rain', 'Dark'): 0.2213302752293578, ('Unknown', 'Dark'): 0.05045871559633028, ('Cloudy', 'Dark'): 0.125, ('Unknown', 'Daylight'): 0.4323394495412844, ('Rain', 'Daylight'): 0.18004587155963303, ('Cloudy', 'Daylight'): 0.21559633027522937, ('Wind', 'Dark'): 0.0045871559633027525, ('Fog', 'Dark'): 0.005733944954128441, ('Other', 'Daylight'): 0.006880733944954129, ('Other', 'Dark'): 0.009174311926605505, ('Fog', 'Daylight'): 0.0022935779816513763, ('Snow', 'Dark'): 0.0011467889908256881, ('Wind', 'Daylight'): 0.0022935779816513763}\n",
            "---------------\n",
            "Bayesian Network (Weather & Visibility Crash Rates)\n",
            "Weather Crash Rates (Lambda)\n",
            "{'Clear': 10.676923076923076, 'Rain': 9.263157894736842, 'Cloudy': 7.317073170731708, 'Wind': 6.0, 'Fog': 7.0}\n",
            "Visibility Crash Rates (Lambda)\n",
            "{'Dark': 9.142857142857142, 'Daylight': 14.903954802259888}\n",
            "---------------\n",
            "Car Injuries & Fatalities\n",
            "Car Injury %:  0.7196376477813603\n",
            "Car Fatality %:  0.007062797481959158\n",
            "Bike Injuries & Fatalities\n",
            "Bike+Pedestrian Injury %:  0.7356205852674067\n",
            "Bike+Pedestrian Fatality %:  0.06861755802219979\n",
            "---------------\n",
            "Speeding\n",
            "0.26998933901918976\n",
            "Hit and Run\n",
            "0.2717217484008529\n",
            "---------------\n",
            "p-values\n",
            "Grab a coffee (10000 samples of a 8000 row list, 8 variables, eta 30mins)\n",
            "p-value (Daylight vs. Dark):  0.4937\n",
            "p-value (Clear vs. Rain):  0.4898\n",
            "p-value (Car vs. Bike+Pedestrian Injuries):  1.0\n",
            "p-value (Car vs. Bike+Pedestrian Fatalities):  0.0\n",
            "---------------\n",
            "Top 10 schools to look at traffic patterns and safety\n",
            "School Crash Statistics\n",
            "[('Washington Elementary', 1373), ('Laurelwood Elementary', 1027), ('Evergreen Valley High', 823), ('Carolyn A. Clark Elementary', 814), ('Rocketship Mateo Sheedy Elementary', 814), ('KIPP Heritage Academy', 800), ('William Faria Elementary', 798), ('Gardner Elementary', 797), ('Jeanne R. Meadows Elementary', 795), ('Foundry School', 790)]\n",
            "School Bike Statistics\n",
            "[('Washington Elementary', 182), ('Laurelwood Elementary', 138), ('Carolyn A. Clark Elementary', 115), ('Rocketship Mateo Sheedy Elementary', 115), ('Robert F. Kennedy Elementary', 111), ('KIPP Heritage Academy', 110), ('Harry Slonaker Academy', 110), ('Evergreen Valley High', 110), ('Gardner Elementary', 109), ('Jeanne R. Meadows Elementary', 109)]\n",
            "---------------\n",
            "Top 10 roads and intersections to look at traffic patterns and safety\n",
            "[('CAPITOL EX', 408), ('STORY RD', 310), ('TULLY RD', 288), ('MONTEREY RD', 274), ('KING RD', 256), ('BLOSSOM HILL RD', 221), ('SANTA CLARA ST', 208), ('FIRST ST', 206), ('SENTER RD', 200), ('WHITE RD', 197)]\n",
            "[('CAPITOL EX,STORY RD', 49), ('KING RD,STORY RD', 45), ('CURTNER AV/TULLY RD,MONTEREY RD', 41), ('CAPITOL EX,TULLY RD', 37), ('BLOSSOM HILL RD,SNELL AV', 37), ('CAPITOL AV,MCKEE RD', 37), ('KING RD,TULLY RD', 33), ('CAPITOL EX,SENTER RD', 32), ('BAYSHORE FR,TULLY RD', 31), ('MCLAUGHLIN AV,TULLY RD', 27)]\n",
            "---------------\n",
            "Top 10 roads and intersections to look at for bike/pedestrian safety\n",
            "[('STORY RD', 46), ('SANTA CLARA ST', 37), ('CAPITOL EX', 33), ('SENTER RD', 31), ('BLOSSOM HILL RD', 30), ('KING RD', 29), ('MONTEREY RD', 28), ('TULLY RD', 27), ('CAPITOL AV', 26), ('ALUM ROCK AV', 24)]\n",
            "[('KING RD,STORY RD', 8), ('BERRYESSA RD,CAPITOL AV', 7), ('FOURTH ST,SANTA CLARA ST', 7), ('ALMADEN EX,CHERRY AV/CHYNOWETH AV', 6), ('MCLAUGHLIN AV,TULLY RD', 5), ('HOPKINS DR,STORY RD', 5), ('MCKEE RD,WHITE RD', 5), ('ALMADEN EX,FOXWORTHY AV', 4), ('CAPITOL EX,MCLAUGHLIN AV', 4), ('KEYES ST,SEVENTH ST', 4)]\n"
          ]
        }
      ],
      "source": [
        "from heapq import nlargest\n",
        "import datetime\n",
        "import gmplot\n",
        "import os\n",
        "import pandas as pd\n",
        "import random as random\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# Datasource references (Santa Clara County, City of San Jose):\n",
        "# Public schools:  https://data-sccphd.opendata.arcgis.com/datasets/e19dc214fb8b451788df878272bb4cea_0/explore\n",
        "# Car crashes:  https://data.sanjoseca.gov/dataset/crashes-data\n",
        "\n",
        "# Global dicts for use across methods\n",
        "counts_dict = {\"Days\" : 0, \"Crashes\" : 0, \"Injuries\" : 0, \"Fatalities\": 0, \"Speeding\": 0, \"HitandRun\": 0, \"Car\": 0, \"Bike\" : 0, \"Pedestrian\": 0, \"CarInjuries\" : 0, \"CarFatalities\": 0, \"BikeInjuries\" : 0, \"BikeFatalities\": 0, \"CrashNearSchool\": 0}\n",
        "school_crash_dict = {}\n",
        "school_bike_dict = {}\n",
        "weather_count = {}\n",
        "weather_crash_info= {}\n",
        "weather_prob_dict = {}\n",
        "visibility_info = {}\n",
        "visibility_count = {}\n",
        "visibility_prob_dict = {}\n",
        "weather_visib_count_dict = {}\n",
        "weather_visib_prob_dict = {}\n",
        "\n",
        "# Global dicts for intersection and roads\n",
        "intersection_dict = {}\n",
        "road_dict = {}\n",
        "bike_intersection_dict = {}\n",
        "bike_road_dict = {}\n",
        "\n",
        "# read each datasource into a dataframe\n",
        "schools = pd.read_csv(\"/content/drive/MyDrive/cs109/data/schools.csv\")\n",
        "crashes_sorted = pd.read_csv(\"/content/drive/MyDrive/cs109/data/crashes_data.csv\").sort_values(by=\"CrashDateTime\", ascending=True)\n",
        "crashes_filtered = []\n",
        "\n",
        "# first, populate all the dicts, then determine crashes by schools, create Google Maps and then crunch stats\n",
        "def main():\n",
        "  populate_general_counts()\n",
        "  crashes_near_schools()\n",
        "  create_maps_visual(\"Car\")\n",
        "  create_maps_visual(\"Bike\")\n",
        "  print_stats()\n",
        "\n",
        "# go through and populate the dicts\n",
        "def populate_general_counts():\n",
        "  print(\"Crunching dataset\")\n",
        "\n",
        "  # get consistent datetime formats\n",
        "  date = datetime.date.fromtimestamp(time.time())\n",
        "  counts_dict[\"Days\"] = (datetime.datetime.now() - convert_to_datetime(crashes_sorted.iloc[2].CrashDateTime, '%m/%d/%Y %I:%M:%S %p')).days\n",
        "\n",
        "  total_crashes = 0\n",
        "  for row in crashes_sorted.itertuples():\n",
        "\n",
        "    # process road and intersection data\n",
        "    road_dict[row.AStreetName] = road_dict.get(row.AStreetName, 0) + 1\n",
        "    road_dict[row.BStreetName] = road_dict.get(row.BStreetName, 0) + 1\n",
        "    intersection_dict[str(row.AStreetName) + \",\" + str(row.BStreetName)] = intersection_dict.get(str(row.AStreetName) + \",\" + str(row.BStreetName), 0) + 1\n",
        "\n",
        "    # drop events where we do not have enough information\n",
        "    if row.Lighting == \"Unknown\" or row.RoadwaySurface == \"Unknown\" or row.Weather == \"Other\" or row.Weather == \"Unknown\":\n",
        "      continue\n",
        "    else:\n",
        "      crashes_filtered.append(row)\n",
        "      if convert_to_datetime(row.CrashDateTime, '%m/%d/%Y %I:%M:%S %p') < datetime.datetime.now():\n",
        "        total_crashes += 1\n",
        "\n",
        "      if row.Injuries >0:\n",
        "        counts_dict[\"Injuries\"] += row.Injuries\n",
        "        if row.VehicleInvolvedWith == \"Bike\" or row.VehicleInvolvedWith == \"Pedestrian\":\n",
        "          counts_dict[\"BikeInjuries\"] += row.Injuries\n",
        "        else:\n",
        "          counts_dict[\"CarInjuries\"] += row.Injuries\n",
        "\n",
        "      if row.FatalInjuries > 0:\n",
        "        counts_dict[\"Fatalities\"] += row.FatalInjuries\n",
        "        if row.VehicleInvolvedWith == \"Bike\" or row.VehicleInvolvedWith == \"Pedestrian\":\n",
        "          counts_dict[\"BikeFatalities\"] += row.FatalInjuries\n",
        "        else:\n",
        "          counts_dict[\"CarFatalities\"] += row.FatalInjuries\n",
        "\n",
        "      if row.VehicleInvolvedWith == \"Bike\":\n",
        "        counts_dict[\"Bike\"] += 1\n",
        "\n",
        "        # process road data\n",
        "        bike_road_dict[row.AStreetName] = bike_road_dict.get(row.AStreetName, 0) + 1\n",
        "        bike_road_dict[row.BStreetName] = bike_road_dict.get(row.BStreetName, 0) + 1\n",
        "        bike_intersection_dict[str(row.AStreetName) + \",\" + str(row.BStreetName)] = bike_intersection_dict.get(str(row.AStreetName) + \",\" + str(row.BStreetName), 0) + 1\n",
        "\n",
        "      elif row.VehicleInvolvedWith == \"Pedestrian\":\n",
        "        counts_dict[\"Pedestrian\"] += 1\n",
        "\n",
        "         # process road data\n",
        "        bike_road_dict[row.AStreetName] = bike_road_dict.get(row.AStreetName, 0) + 1\n",
        "        bike_road_dict[row.BStreetName] = bike_road_dict.get(row.BStreetName, 0) + 1\n",
        "        bike_intersection_dict[str(row.AStreetName) + \",\" + str(row.BStreetName)] = bike_intersection_dict.get(str(row.AStreetName) + \",\" + str(row.BStreetName), 0) + 1\n",
        "      else:\n",
        "        counts_dict[\"Car\"] += 1\n",
        "\n",
        "      if row.SpeedingFlag == True:\n",
        "        counts_dict[\"Speeding\"] += 1\n",
        "\n",
        "      if row.HitAndRunFlag == True:\n",
        "        counts_dict[\"HitandRun\"] += 1\n",
        "\n",
        "      date = convert_to_datetime(row.CrashDateTime, '%m/%d/%Y %I:%M:%S %p')\n",
        "      date = date.strftime(\"%Y-%m-%d\")\n",
        "      weather_count[date] = row.Weather\n",
        "\n",
        "      visibility = row.Lighting\n",
        "      if \"Dark\" in str(row.Lighting) or \"Dusk\" in str(row.Lighting):\n",
        "        visibility = \"Dark\"\n",
        "      elif \"Daylight\" in str(row.Lighting):\n",
        "        visibility = \"Daylight\"\n",
        "      else:\n",
        "        visibility = \"Unknown\"\n",
        "\n",
        "        # check the time of the crash to determine\n",
        "        if convert_to_datetime(row.CrashDateTime, '%m/%d/%Y %I:%M:%S %p').hour >= 7 and convert_to_datetime(row.CrashDateTime, '%m/%d/%Y %I:%M:%S %p').hour < 19:\n",
        "          visibility = \"Daylight\"\n",
        "        else:\n",
        "          visibility = \"Dark\"\n",
        "\n",
        "      visibility_count[date] = visibility\n",
        "      counts_dict[\"Crashes\"] = total_crashes\n",
        "\n",
        "# go through and determine crashes near schools and vehicle involvement\n",
        "def crashes_near_schools():\n",
        "  for crash in crashes_sorted.itertuples():\n",
        "    for school in schools.itertuples():\n",
        "      # check distance of crash to each school and if its under quarter-mile\n",
        "      if (abs(school.LATITUDE - crash.Latitude)) <= quarter_mile_latitude_diff():\n",
        "        counts_dict[\"CrashNearSchool\"] += 1\n",
        "        # get crash information\n",
        "        school_crash_dict[school.PLACENAME] = school_crash_dict.get(school.PLACENAME, 0) + 1\n",
        "\n",
        "        # look for bike or pedestrian involvement\n",
        "        if crash.VehicleInvolvedWith == \"Bike\" or crash.VehicleInvolvedWith == \"Pedestrian\":\n",
        "          school_bike_dict[school.PLACENAME] = school_bike_dict.get(school.PLACENAME, 0) + 1\n",
        "\n",
        "    # populate weather and visibility\n",
        "    weather_crash_info[crash.Weather] = weather_crash_info.get(crash.Weather, 0) + 1\n",
        "\n",
        "    visibility = crash.Lighting\n",
        "    if \"Dark\" in str(crash.Lighting) or \"Dusk\" in str(crash.Lighting):\n",
        "      visibility = \"Dark\"\n",
        "    elif \"Daylight\" in str(crash.Lighting):\n",
        "      visibility = \"Daylight\"\n",
        "    else:\n",
        "      visibility = \"Unknown\"\n",
        "\n",
        "      # check the time of the crash to determine\n",
        "      if convert_to_datetime(crash.CrashDateTime, '%m/%d/%Y %I:%M:%S %p').hour >= 7 and convert_to_datetime(crash.CrashDateTime, '%m/%d/%Y %I:%M:%S %p').hour < 19:\n",
        "        visibility = \"Daylight\"\n",
        "      else:\n",
        "        visibility = \"Dark\"\n",
        "\n",
        "    visibility_info[visibility] = visibility_info.get(visibility, 0) + 1\n",
        "\n",
        "# utility method to convert to a consistent datetime\n",
        "def convert_to_datetime(date_str, format):\n",
        "    format_string = '%m/%d/%Y %I:%M:%S %p'\n",
        "    datetime_obj = datetime.datetime.now()\n",
        "\n",
        "    # Parse the date string into a datetime object\n",
        "    if not isinstance(date_str, float):\n",
        "      datetime_obj = datetime.datetime.strptime(date_str, format_string)\n",
        "\n",
        "    return datetime_obj\n",
        "\n",
        "# create a Bayesian network model for weather and visibilitiy given a crash\n",
        "# calculate weather and visibility MLE rates\n",
        "def create_bayesian_model():\n",
        "  # populate weather bayesian nodes\n",
        "  for weather in weather_crash_info:\n",
        "    total_days_weather = sum(1 for v in weather_count.values() if v == weather)\n",
        "    if total_days_weather > 0:\n",
        "      weather_prob_dict[weather] = weather_crash_info[weather] / total_days_weather\n",
        "\n",
        "  # populate visibility bayesian nodes\n",
        "  for visibility in visibility_info:\n",
        "    total_days_visibility = sum(1 for v in visibility_count.values() if v == visibility)\n",
        "    if total_days_visibility > 0:\n",
        "      visibility_prob_dict[visibility] = visibility_info[visibility] / total_days_visibility\n",
        "\n",
        "  # now populate the joint matrix\n",
        "  for crash in crashes_sorted.itertuples():\n",
        "    visibility = crash.Lighting\n",
        "    if \"Dark\" in str(crash.Lighting) or \"Dusk\" in str(crash.Lighting):\n",
        "      visibility = \"Dark\"\n",
        "      weather_visib_count_dict[crash.Weather, visibility] = weather_visib_count_dict.get((crash.Weather, visibility), 0) + 1\n",
        "    elif \"Daylight\" in str(crash.Lighting):\n",
        "      visibility = \"Daylight\"\n",
        "      weather_visib_count_dict[crash.Weather, visibility] = weather_visib_count_dict.get((crash.Weather, visibility), 0) + 1\n",
        "\n",
        "  for i in weather_visib_count_dict:\n",
        "    weather_visib_prob_dict[i] = weather_visib_count_dict[i] / counts_dict[\"Days\"]\n",
        "\n",
        "  print(\"Joint Lambda\")\n",
        "  print(weather_visib_prob_dict)\n",
        "\n",
        "# utilizing gmplot, create 2 Google Maps visuals to navigate school crash data\n",
        "def create_maps_visual(involvement):\n",
        "  GOOGLE_MAPS_API = \"AIzaSyB2LJZZb5p-t8zS6pf8C9Xwf3p1gPcTmYM\"\n",
        "  gmap2 = gmplot.GoogleMapPlotter.from_geocode(\"San Jose, California\", apikey=GOOGLE_MAPS_API)\n",
        "\n",
        "  if involvement == \"Bike\" or involvement == \"Pedestrian\":\n",
        "    for school in school_bike_dict:\n",
        "\n",
        "      # get school lat/long\n",
        "      school_lat = schools[schools.PLACENAME == school].LATITUDE.values[0]\n",
        "      school_long = schools[schools.PLACENAME == school].LONGITUDE.values[0]\n",
        "\n",
        "      # get crash stats per school\n",
        "      crash_count = school_bike_dict[school]\n",
        "\n",
        "      # plot on map\n",
        "      gmap2.circle(school_lat, school_long, radius=crash_count, color=\"blue\")\n",
        "      gmap2.marker(school_lat, school_long, title=school+\" \"+str(crash_count))\n",
        "\n",
        "    gmap2.draw(\"bike_crashes.html\")\n",
        "    print(\"Generated Google Maps visual: bike_crashes.html\")\n",
        "  else:\n",
        "    for school in school_crash_dict:\n",
        "\n",
        "      # get school lat/long\n",
        "      school_lat = schools[schools.PLACENAME == school].LATITUDE.values[0]\n",
        "      school_long = schools[schools.PLACENAME == school].LONGITUDE.values[0]\n",
        "\n",
        "      # get crash stats per school\n",
        "      crash_count = school_crash_dict[school]\n",
        "\n",
        "      # plot on map\n",
        "      gmap2.circle(school_lat, school_long, radius=crash_count, color=\"red\")\n",
        "      gmap2.marker(school_lat, school_long, title=school+\" \"+str(crash_count))\n",
        "\n",
        "    gmap2.draw(\"car_crashes.html\")\n",
        "    print(\"Generated Google Maps visual: car_crashes.html\")\n",
        "\n",
        "# utility method to calculate a quarter mile from a latitude\n",
        "def quarter_mile_latitude_diff():\n",
        "    earth_circumference = 24901  # miles\n",
        "    degrees_latitude = 360\n",
        "    distance_per_degree = earth_circumference / degrees_latitude  # miles/degree\n",
        "    quarter_mile = 0.25  # miles\n",
        "    latitude_diff = quarter_mile / distance_per_degree  # degrees\n",
        "\n",
        "    return latitude_diff\n",
        "\n",
        "def filter_crash_visibility_list(value, crashes):\n",
        "  filtered_crashes = []\n",
        "  for crash in crashes.itertuples():\n",
        "    if value in str(crash.Lighting):\n",
        "      filtered_crashes.append(crash)\n",
        "  return pd.DataFrame(filtered_crashes)\n",
        "\n",
        "# calculate the pvalue for visibility (Daylight, Dark)\n",
        "def visibility_pvalue_boot(value1, value2):\n",
        "  value1_count = visibility_filtering_function(value1, value2, crashes_sorted)[1]\n",
        "  value2_count = visibility_filtering_function(value1, value2, crashes_sorted)[2]\n",
        "  value1_crash_list = filter_crash_visibility_list(value1, crashes_sorted)\n",
        "  value2_crash_list = filter_crash_visibility_list(value2, crashes_sorted)\n",
        "  uniform = value1_crash_list + value2_crash_list\n",
        "  observed_diff = visibility_filtering_function(value1, value2, uniform)[0]\n",
        "\n",
        "  count = 0\n",
        "  for i in range(10000):\n",
        "    value1_boot = uniform.sample(len(value1_crash_list), replace=True)\n",
        "    value2_boot = uniform.sample(len(value2_crash_list), replace=True)\n",
        "\n",
        "    value1_mean = visibility_filtering_function(value1, value2, value1_boot)[1]/len(value1_boot)\n",
        "    value2_mean = visibility_filtering_function(value1, value2, value2_boot)[2]/len(value2_boot)\n",
        "    boot_diff = value1_mean - value2_mean\n",
        "    if boot_diff > observed_diff:\n",
        "      count += 1\n",
        "  return count / 10000\n",
        "\n",
        "# filter the crash list for particular visibility details and get the diff of means\n",
        "def visibility_filtering_function(value1, value2, crash_list):\n",
        "  value1_count = 0\n",
        "  value2_count = 0\n",
        "  for i in crash_list.itertuples():\n",
        "    if value1 in str(i.Lighting):\n",
        "      value1_count += 1\n",
        "    elif value2 in str(i.Lighting):\n",
        "      value2_count += 1\n",
        "  return abs((value1_count/len(crash_list)) - (value2_count/len(crash_list))), value1_count, value2_count\n",
        "\n",
        "def filter_crash_weather_list(value, crashes):\n",
        "  filtered_crashes = []\n",
        "  for crash in crashes.itertuples():\n",
        "    if value in str(crash.Weather):\n",
        "      filtered_crashes.append(crash)\n",
        "  return pd.DataFrame(filtered_crashes)\n",
        "\n",
        "# calculate the pvalue for weather (Clear, Rain)\n",
        "def weather_pvalue_boot(value1, value2):\n",
        "  value1_count = weather_filtering_function(value1, value2, crashes_sorted)[1]\n",
        "  value2_count = weather_filtering_function(value1, value2, crashes_sorted)[2]\n",
        "  value1_crash_list = filter_crash_weather_list(value1, crashes_sorted)\n",
        "  value2_crash_list = filter_crash_weather_list(value2, crashes_sorted)\n",
        "  uniform = value1_crash_list + value2_crash_list\n",
        "  observed_diff = weather_filtering_function(value1, value2, uniform)[0]\n",
        "\n",
        "  count = 0\n",
        "  for i in range(10000):\n",
        "    value1_boot = uniform.sample(len(value1_crash_list), replace=True)\n",
        "    value2_boot = uniform.sample(len(value2_crash_list), replace=True)\n",
        "\n",
        "    value1_mean = weather_filtering_function(value1, value2, value1_boot)[1]/len(value1_boot)\n",
        "    value2_mean = weather_filtering_function(value1, value2, value2_boot)[2]/len(value2_boot)\n",
        "    boot_diff = value1_mean - value2_mean\n",
        "    if boot_diff > observed_diff:\n",
        "      count += 1\n",
        "  return count / 10000\n",
        "\n",
        "# filter the crash list for particular weather details and get the diff of means\n",
        "def weather_filtering_function(value1, value2, crash_list):\n",
        "  value1_count = 0\n",
        "  value2_count = 0\n",
        "  for i in crash_list.itertuples():\n",
        "    if value1 in str(i.Weather):\n",
        "      value1_count += 1\n",
        "    elif value2 in str(i.Weather):\n",
        "      value2_count += 1\n",
        "  return abs((value1_count/len(crash_list)) - (value2_count/len(crash_list))), value1_count, value2_count\n",
        "\n",
        "# calculate the pvalue for vehicle involvement (Car, Bike+Pedestrian)\n",
        "def vehicle_pvalue(category):\n",
        "  value1_count = counts_dict[\"Car\"]\n",
        "  value2_count = counts_dict[\"Bike\"] + counts_dict[\"Pedestrian\"]\n",
        "  observed_diff = abs((counts_dict[\"Car\"+str(category)] / counts_dict[\"Car\"]) - (counts_dict[\"Bike\"+str(category)] / (counts_dict[\"Bike\"] + counts_dict[\"Pedestrian\"])))\n",
        "\n",
        "  count = 0\n",
        "  for i in range(10000):\n",
        "    value1_boot = crashes_sorted.sample(value1_count, replace=True)\n",
        "    value2_boot = crashes_sorted.sample(value2_count, replace=True)\n",
        "\n",
        "    value1_mean = filter_vehicle_involvement(category, \"Car\", value1_boot)\n",
        "    value2_mean = filter_vehicle_involvement(category, \"Bike\", value2_boot) + filter_vehicle_involvement(category, \"Pedestrian\", value2_boot)\n",
        "    boot_diff = abs(value1_mean - value2_mean)\n",
        "    if boot_diff > observed_diff:\n",
        "      count += 1\n",
        "  return count / 10000\n",
        "\n",
        "# filter utility to get the mean of vehicle involvement in dataset\n",
        "def filter_vehicle_involvement(category, vehicle, data):\n",
        "  count = 0\n",
        "  for i in data.itertuples():\n",
        "    if category == \"Fatalities\":\n",
        "      if i.FatalInjuries > 0:\n",
        "        if vehicle == \"Car\":\n",
        "          if \"Bike\" not in str(i.VehicleInvolvedWith) or \"Pedestrian\" not in str(i.VehicleInvolvedWith):\n",
        "            count += 1\n",
        "        else:\n",
        "          if vehicle in str(i.VehicleInvolvedWith):\n",
        "            count += 1\n",
        "    else:\n",
        "      if i.Injuries > 0:\n",
        "        if vehicle == \"Car\":\n",
        "          if \"Bike\" not in str(i.VehicleInvolvedWith) or \"Pedestrian\" not in str(i.VehicleInvolvedWith):\n",
        "            count += 1\n",
        "        else:\n",
        "          if vehicle in str(i.VehicleInvolvedWith):\n",
        "            count += 1\n",
        "  return count/len(data)\n",
        "\n",
        "def calculate_pvalues():\n",
        "  print(\"p-value (Daylight vs. Dark): \", visibility_pvalue_boot(\"Daylight\", \"Dark\"))\n",
        "  print(\"p-value (Clear vs. Rain): \", weather_pvalue_boot(\"Clear\", \"Rain\"))\n",
        "  print(\"p-value (Car vs. Bike+Pedestrian Injuries): \", vehicle_pvalue(\"Injuries\"))\n",
        "  print(\"p-value (Car vs. Bike+Pedestrian Fatalities): \", vehicle_pvalue(\"Fatalities\"))\n",
        "\n",
        "def print_stats():\n",
        "  # crashes per day lambda\n",
        "  crash_lambda = counts_dict[\"Crashes\"] / counts_dict[\"Days\"]\n",
        "  bike_lambda = (counts_dict[\"Bike\"] + counts_dict[\"Pedestrian\"]) / counts_dict[\"Days\"]\n",
        "\n",
        "  print(\"Summary Stats\")\n",
        "  print(\"Time Period for Analysis (in Days): \", counts_dict[\"Days\"])\n",
        "  print(\"Time Period for each Lambda:  day\")\n",
        "  print(\"---------------\")\n",
        "  print(\"Maximum Likelihood Estimation (Car, Bike, Pedestrian Crash Rates)\")\n",
        "  print(\"Overall Car Crash Lambda: \", crash_lambda)\n",
        "  print(\"Overall Bike/Pedestrian Involvement Lambda: \", bike_lambda)\n",
        "  create_bayesian_model()\n",
        "\n",
        "  print(\"---------------\")\n",
        "  print(\"Bayesian Network (Weather & Visibility Crash Rates)\")\n",
        "  print(\"Weather Crash Rates (Lambda)\")\n",
        "  print(weather_prob_dict)\n",
        "\n",
        "  print(\"Visibility Crash Rates (Lambda)\")\n",
        "  print(visibility_prob_dict)\n",
        "\n",
        "  print(\"---------------\")\n",
        "  print(\"Car Injuries & Fatalities\")\n",
        "  print(\"Car Injury %: \", counts_dict[\"CarInjuries\"] / counts_dict[\"Car\"])\n",
        "  print(\"Car Fatality %: \", counts_dict[\"CarFatalities\"] / counts_dict[\"Car\"])\n",
        "\n",
        "  print(\"Bike Injuries & Fatalities\")\n",
        "  print(\"Bike+Pedestrian Injury %: \", counts_dict[\"BikeInjuries\"] / (counts_dict[\"Bike\"] + counts_dict[\"Pedestrian\"]))\n",
        "  print(\"Bike+Pedestrian Fatality %: \", counts_dict[\"BikeFatalities\"] / (counts_dict[\"Bike\"] + counts_dict[\"Pedestrian\"]))\n",
        "\n",
        "  print(\"---------------\")\n",
        "  print(\"Speeding\")\n",
        "  print(counts_dict[\"Speeding\"] / counts_dict[\"Crashes\"])\n",
        "  print(\"Hit and Run\")\n",
        "  print(counts_dict[\"HitandRun\"] / counts_dict[\"Crashes\"])\n",
        "\n",
        "  print(\"---------------\")\n",
        "  print(\"p-values\")\n",
        "  print(\"Grab a coffee (10000 samples of a 8000 row list, 8 variables, eta 45mins)\")\n",
        "  calculate_pvalues()\n",
        "\n",
        "  print(\"---------------\")\n",
        "  print(\"Top 10 schools to look at traffic patterns and safety\")\n",
        "  print(\"School Crash Statistics\")\n",
        "  print(nlargest(10, school_crash_dict.items(), key=lambda x: x[1]))\n",
        "  print(\"School Bike Statistics\")\n",
        "  print(nlargest(10, school_bike_dict.items(), key=lambda x: x[1]))\n",
        "\n",
        "  print(\"---------------\")\n",
        "  print(\"Top 10 roads and intersections to look at traffic patterns and safety\")\n",
        "  print(nlargest(10, road_dict.items(), key=lambda x: x[1]))\n",
        "  print(nlargest(10, intersection_dict.items(), key=lambda x: x[1]))\n",
        "\n",
        "  print(\"---------------\")\n",
        "  print(\"Top 10 roads and intersections to look at for bike/pedestrian safety\")\n",
        "  print(nlargest(10, bike_road_dict.items(), key=lambda x: x[1]))\n",
        "  print(nlargest(10, bike_intersection_dict.items(), key=lambda x: x[1]))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1XfMJuXbC_xp3PSfDhZ0zznaD5623AEFa",
      "authorship_tag": "ABX9TyPU3+0JKdfPKIR6XWOeR8kL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}